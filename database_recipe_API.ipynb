{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379d55ec",
   "metadata": {},
   "source": [
    "# Welcome to our Edamame API scraper :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45411a70",
   "metadata": {},
   "source": [
    "Let's get ready for scraping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d6d1ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6e71870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose diet (for example paleo)\n",
    "diet = 'paleo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "60450413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get acces API\n",
    "url = \"https://api.edamam.com/api/recipes/v2\"\n",
    "\n",
    "api_id = os.environ['APP_ID']\n",
    "api_key = os.environ['APP_KEY'] \n",
    "\n",
    "headers = {api_id, api_key}\n",
    "\n",
    "querystring = {\"type\": \"public\", \"q\": diet, \"app_id\": api_id, \"app_key\": api_key}\n",
    "\n",
    "response = requests.get(url, headers={\"Authorization\": api_key}, params=querystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "527cc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Json for data\n",
    "json_response = json.loads(response.text.replace('null', '\"None\"').replace('True','\"True\"').replace('False','\"False\"'))\n",
    "recipe_request = json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "600b7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to next url\n",
    "still_some_data = True\n",
    "next_url=url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296ab246",
   "metadata": {},
   "source": [
    "# Extract all raw data for this diet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474fd223",
   "metadata": {},
   "source": [
    "This code snippet loops through all pages of the API for this recipe and extracts all data.\n",
    "In order to create a dataset with recipes of multiple diets, you should change the diet in the 'choose diet' snippet and run this part multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b51cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all data for this specific diet \n",
    "count = 0 \n",
    "full_df_list = []\n",
    "while still_some_data:\n",
    "    response = requests.get(next_url, headers={\"Authorization\": api_key}, params=querystring)\n",
    "    try: \n",
    "      response.json()\n",
    "    except:\n",
    "      still_some_data = False\n",
    "    try:\n",
    "      recipe_request = response.json()\n",
    "    except:\n",
    "      print('headersize: ', print(len(next_url)))\n",
    "      print(response.text) \n",
    "    time.sleep(6)\n",
    "    \n",
    "    try:\n",
    "        print(f'Getting data for '+str(recipe_request['to']))\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"There was a problem accessing the equipment data.\")\n",
    "        \n",
    "    if recipe_request['to']==recipe_request['count']:\n",
    "        still_some_data=False\n",
    "    if recipe_request['to']> recipe_request['count']:\n",
    "        still_some_data = False \n",
    "        \n",
    "    next_url = recipe_request['_links']['next']['href']\n",
    "\n",
    "    for idx, recipe in enumerate(recipe_request['hits']):\n",
    "        count+=1 \n",
    "        full_df_list.append([recipe[\"recipe\"]])\n",
    "        \n",
    "    f = open(diet+'_raw_data.json','a',encoding='utf-8')\n",
    "    f.write(json.dumps(full_df_list))\n",
    "    f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09348b24",
   "metadata": {},
   "source": [
    "# Extract macronutrients of recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086c3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through pages and extract recipe name, cuisine type and macronutrients\n",
    "count = 0 \n",
    "df_list = []\n",
    "while still_some_data:\n",
    "    response = requests.get(next_url, headers={\"Authorization\": api_key}, params=querystring)\n",
    "    try: \n",
    "      response.json()\n",
    "    except:\n",
    "      still_some_data = False\n",
    "    try:\n",
    "      recipe_request = response.json()\n",
    "    except:\n",
    "      print('headersize: ', print(len(next_url)))\n",
    "      print(response.text) \n",
    "    time.sleep(6)\n",
    "    \n",
    "    try:\n",
    "        print(f'Getting data for '+str(recipe_request['to']))\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print(\"There was a problem accessing the equipment data.\")\n",
    "        \n",
    "    if recipe_request['to']==recipe_request['count']:\n",
    "        still_some_data=False\n",
    "    if recipe_request['to']> recipe_request['count']:\n",
    "        still_some_data = False \n",
    "        \n",
    "    next_url = recipe_request['_links']['next']['href']\n",
    "\n",
    "    for idx, recipe in enumerate(recipe_request['hits']):\n",
    "      count+=1\n",
    "      if (recipe[\"recipe\"][\"mealType\"][0]== 'lunch/dinner'):\n",
    "        # print(recipe[\"recipe\"][\"label\"])\n",
    "        df_list.append([str(diet), \\\n",
    "            recipe[\"recipe\"][\"label\"], \\\n",
    "            recipe[\"recipe\"][\"cuisineType\"][0], \\\n",
    "            float(round(recipe['recipe'][\"totalNutrients\"]['PROCNT']['quantity'], 2)), \\\n",
    "            float(round(recipe['recipe'][\"totalNutrients\"]['CHOCDF']['quantity'], 2)),\\\n",
    "            float(round(recipe['recipe'][\"totalNutrients\"]['FAT']['quantity'], 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90678906",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_json = json.dumps(full_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for single diet\n",
    "df = pd.DataFrame(df_list, columns = ['Diet_type', 'Recipe_name', 'Cuisine_type', 'Protein(g)', 'Carbs(g)', 'Fat(g)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cca3ba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data from single diet into CSV. \n",
    "df.to_csv(\"%s.csv\" % diet, index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7fc386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Or read pandas\n",
    "pd.read_csv(\"%s.csv\" % diet) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3e463",
   "metadata": {},
   "source": [
    "# Merge the data of different diets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e31ef12",
   "metadata": {},
   "source": [
    "If you wish to compare data of different diets, you can merge the CSV's. Just extend the list and the code snippet will form a data frame for all diets. For now, we made a dataframe for Paleo, Keto, Dash, Vegan and Mediterranean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e69a0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the files. You dan add more files in the list. \n",
    "# Type CSV names of the diets you extracted data from\n",
    "df_all_diets = pd.concat(\n",
    "    map(pd.read_csv, ['../recipe-nutritions/CSV/paleo.csv', '../recipe-nutritions/CSV/vegan.csv', '../recipe-nutritions/CSV/keto.csv', '../recipe-nutritions/CSV/mediterranean.csv', '../recipe-nutritions/CSV/dash.csv']), ignore_index=True)\n",
    "print(df_all_diets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1aab7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged dataframe into CSV\n",
    "df_all_diets.to_csv('All_Diets.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or read pandas\n",
    "pd.read_csv('All_Diets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
